
# Clustering Analysis and KPI Computation

This project performs clustering analysis on agricultural data to identify patterns and compute cluster-based Key Performance Indicators (KPIs). 
The script loads a dataset, performs feature engineering, optimizes the number of clusters using the elbow method, and visualizes clustering results.

Ultimately, for further agent-based simulation, the script exports a .json file with descriptive statistics of each feature and across all clusters.

## Prerequisites

Before running the code, ensure that you have the following Python libraries installed:

- `numpy`
- `pandas`
- `matplotlib`
- `tqdm`
- `seaborn`

You can install these libraries using pip if they are not already installed:

```bash
pip install numpy pandas matplotlib tqdm
```

## Project Structure

```
.
├── data/
│   └── flat_df.csv  # Input data (example CSV file)
├── output/          # Directory where output files are saved
├── clustering.py    # Contains clustering functions used in the script
└── 03_new_features_and_clustering.py   # Main script for ML section (described below)
```

## Running the Script

The script must be run from the main workind directory; namely, ecowheataly.
Thus, firs cd into that repository and then proceed with the following steps.

### Step 1: Prepare Data

Ensure you have a `flat_df.csv` file in the `data/` directory. This CSV file contains the input data required for clustering.
The data can be generated by running, in sequence, `01_create_json_database_for_lca_ADP.py` and `02_load_json_database_for_ML_ADP.py`.

### Step 2: Run the Script

To execute the script, run the following command from the command line:

```bash
python3 03_new_features_and_clustering.py
```

### Script Parameters

- `year`: Optional parameter that filters the data by a specific year (default is 2016). You can change this value by modifying the `main(year)` function call in the script.

### Outputs

The script generates several outputs:

1. **Optimal Number of Clusters**: Computes and prints the optimal number of clusters using the elbow method.
2. **Cluster KPI JSON File**: Saves cluster statistics as a JSON file in the `output/` directory.
3. **Cluster Visualizations**: Generates and displays plots to visualize clustering results.

### Description of Key Functions

- `_get_cluster_stats(clustered_df: pd.DataFrame)`: Computes statistics for each cluster.
- `_compute_optimal_k(result_df: pd.DataFrame)`: Finds the optimal number of clusters using the elbow method based on inertia.
- `main(year: int)`: Main function that performs data loading, feature engineering, clustering, and visualization.

### Customization

- You can change the input columns used for clustering by modifying the `input_l` list in the script.
- Modify visualization settings or clustering parameters based on your requirements.

### Features engineering

The pipeline is composed by various steps, including:
- Identify all columns related to herbicides: 
    - This step filters columns that contain data related to herbicide quantities based on their names containing "Herbicide_Qt".

- Calculate farm yield: 
    -The farm yield is computed as the produced quantity divided by crop acreage. This provides a per-hectare measurement of production efficiency for the crop.

- Compute the herbicide ratio relative to crop acreage: 
    - This step sums up all herbicide-related columns for each row and normalizes the value by dividing it by the total crop acreage. This gives an indication of herbicide use per unit area.

Likewise, the definition of performance ratios follows the following schema:
- Calculate the ratio of herbicide use relative to yield: 
    -This ratio is obtained by dividing the computed herbicide_ratio by the farm_yield. It serves as a measure of herbicide efficiency relative to the yield produced.

- Define columns representing essential elements for crop nutrition: 
    - The columns nitrogen_ha, phosphorus_ha, and potassium_ha are identified as key elements contributing to crop growth.

- Calculate total elements ratio over yield: 
    - This ratio sums up the essential nutrient elements per hectare and normalizes it by the farm yield, providing insight into nutrient usage relative to yield efficiency.

- Calculate hours of machinery use per hectare relative to yield: 
    - This feature divides the hours of machinery use per hectare by the farm yield to determine machinery usage efficiency for each unit of yield produced.

Ultimately, relevant columns, for clustering purposes, are filtered. These include:
- herbicide_ratio_over_yield
- elements_ratio_over_yield
- hours_of_machines_ha_over_yield

These features capture key performance metrics and efficiency ratios for use in clustering analysis to better understand data patterns and relationships.

### ML section
Implemented techniques include, sequentially:

- Outlier Detection (default values is Isolation Forest for consistency purposes):
    - Isolation Forest: An ensemble method that isolates anomalies instead of profiling normal data. It works well for multidimensional data and is efficient in detecting outliers.
    - Gaussian Mixture Model (GMM): Uses a probabilistic approach to model the distribution of data points and detect outliers based on scores derived from the GMM distribution.
    - One-Class SVM: A method based on support vector machines that finds a decision boundary to distinguish normal data points from outliers. This method is useful for novelty detection.

- Data Standardization:
    - The StandardScaler is used to standardize features to have a mean of zero and a unit variance, which is a necessary step for many clustering algorithms to function correctly.

- Clustering Algorithms (default choice, is KMeans for performance and sparsity-related considerations):
    - KMeans: Partitions data into k clusters by minimizing the variance within clusters, commonly used for its simplicity and interpretability.
    - DBSCAN (Density-Based Spatial Clustering of Applications with Noise): A clustering algorithm that groups points closely packed together and labels points that lie in low-density regions as outliers.
    - Silhouette score and inertia: These metrics are used to assess the quality of the clustering by evaluating how well each data point fits within its cluster compared to other clusters.

The script integrates these techniques to preprocess data, detect and remove outliers, cluster the data using various algorithms, and visualize the resulting clusters, providing valuable insights into the underlying structure of the data.


Happy clustering!
